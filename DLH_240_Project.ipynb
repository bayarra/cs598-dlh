{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLH_240_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bayarra/cs598-dlh/blob/main/DLH_240_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Paper 240. Application of deep and machine learning techniques for multi-label classification performance on psychotic disorder diseases\n",
        "\n"
      ],
      "metadata": {
        "id": "tAHZWthrOAQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PART 1: Accessing the Study and its Dataset.\n",
        "\n",
        "###How to access the Study\n",
        "\n",
        "To pdf version of this study can be accessed at [this link](https://www.sciencedirect.com/science/article/pii/S2352914821000356). \n",
        "\n",
        "###How to access the Dataset\n",
        "\n",
        "To access this dataset, you will need to download the CSV from [this](https://www.sciencedirect.com/science/article/pii/S2352340917303487) link. This is an additional study that is cited in our study. \n",
        "\n",
        "The link to download our dataset is present in the section \"*Appendix A. Supplementary material*\"\n",
        "\n",
        "Clicking on this link in this section will give you the option to locally download the dataset that is being used here in the CSV format. \n",
        "\n",
        "###How to Mount (Add) this Dataset to the Google Collabatory Notebook\n",
        "\n",
        "In order to import this dataset into the Google Collabatory Drive, you will need to upload the CSV into your Google Drive account, and then execute the following code block \n",
        "\n",
        "####NOTE: This code block is already in the Collab Notebook in PART 3. You do NOT need to do this again.\n",
        "```\n",
        "drive.mount('/content/drive/')\n",
        "path = \"/content/drive/MyDrive/mmc240_c.csv\"\n",
        "df = pd.read_csv(path)\n",
        "```\n",
        "This code block does the following steps:\n",
        "\n",
        "1. Mounts your Google drive to this collabatory notebook\n",
        "\n",
        "2. Pandas will attempt to go to the path and open the file, while converting it to a dataframe.\n"
      ],
      "metadata": {
        "id": "9mTz4TQD4mgZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PART 2: Dependency Description.\n",
        "\n",
        "The following is a list of all of the packages used in this Collabatory Notebook in order to run this project. A brief description of each dependency and its purpose is below.\n",
        "\n",
        "Basic libraries that allow for dataset modification\n",
        "\n",
        "```\n",
        "#pandas allows us to easily modify and one hot encode the values in the dataset.\n",
        "import pandas as pd\n",
        "\n",
        "# numpy is used to convert the values in our dataset into a tensor for the Neural Network. \n",
        "import numpy as np\n",
        "\n",
        "# test_train_split is used to split the dataset into the correct ratios as specified in the original study.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "This library allows the Google Collab Notebook to access Google Drive and mount it, so that the CSV file can be accessed.\n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "\n",
        "\"\"\"\n",
        "SMOTE is an algorithm that is used to balance the dataset. This helps us get a more realistic picture of how accurate the Neural Networks are.\n",
        "\"\"\"\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\"\"\"\n",
        "skelarn LabelEncoder is an encoder that will convert Strings and Characters into integers. This is helpful when we want to convert basic attributes of our dataset into simple binary values (such as 0 and 1)\n",
        "\"\"\"\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "```\n",
        "Classic Machine Learning Models\n",
        "\n",
        "```\n",
        "\"\"\"\n",
        "MLPClassifier, LinearSVC, RandomForestClassifier, and DecisionTreeClassifier from Sklearn allow us to easily run the MLP, SVM, RF, and\n",
        "DT Machine Learning Algorithms as a baseline to compare the Neural Networks to without requiring us to have to build each\n",
        "algorithm from scratch.\n",
        "\"\"\"\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "```\n",
        "\n",
        "Keras API and it's dependencies (Used to Build the Neural Networks in this study)\n",
        "```\n",
        "\"\"\"\n",
        "Because the Keras API uses Tensors, this is required to convert our pandas dataframe to a tensor\n",
        "\"\"\" \n",
        "import tensorflow as tf\n",
        "\n",
        "\"\"\"\n",
        "This is the basic Keras API which is used to set up the Neural Network Model\n",
        "\"\"\"\n",
        "from tensorflow import keras\n",
        "\"\"\"\n",
        "These are the basic types of Keras Neural Network models that we use in order to build the Neural Network\n",
        "\"\"\"\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "\n",
        "\"\"\"\n",
        "These represents the various layers that we use in the Neural Network to build what is described in the original study.\n",
        "\"\"\"\n",
        "from tensorflow.keras.layers import Dense,Input,Dropout,Flatten,Conv2D,MaxPool2D\n",
        "\n",
        "\"\"\"\n",
        "this part of Keras allows us to convert a dataframe into a numpy array that can then be converted into a tensor. This is important in Part 12, when we are required to hot encode target, which converts to a pandas dataframe. This library helps convert that dataframe into a numpy array which can then be converted directly into a tensor that can be used in the Neural Network model.\n",
        "\"\"\"\n",
        "from keras.utils import np_utils\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "O4OVkqk5iTwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PART 3: Installing Basic Dependencies, Taking a look at the dataset in raw form.\n",
        "\n",
        "In this section, we will import/install the basic dependencies for this project and then, attempt to load/view the CSV file via the instructions mentioned above.\n",
        "\n",
        "To do this, we will run the these two blocks, which will import all of our dependcies and load the Raw CSV dataset into the Collabatory Notebook environment. "
      ],
      "metadata": {
        "id": "_pf3fgQS9aVI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhJqZVArNk_X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')\n",
        "path = \"/content/drive/MyDrive/mmc240_c.csv\"\n",
        "df = pd.read_csv(path)\n",
        "df"
      ],
      "metadata": {
        "id": "Dt0PPhgkPWWp",
        "outputId": "5fed265b-0dc3-4d69-f34f-fa84fe06c53c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    sex  age faNoily_status religion occupation genetic status loss_of_parent  \\\n",
              "0     M   18            Yes        C    STUDENT     Yes      S            Yes   \n",
              "1     F   30            Yes        M    ARTISAN     Yes      S            Yes   \n",
              "2     M   22            Yes        C    STUDENT      No      S             No   \n",
              "3     M   35             No        M    ARTISAN      No      M             No   \n",
              "4     M   30            Yes        M    ARTISAN     Yes      M             No   \n",
              "..   ..  ...            ...      ...        ...     ...    ...            ...   \n",
              "495   F   73            Yes        M    RETIRED     Yes      S            Yes   \n",
              "496   F   50             No        M    ARTISAN      No      M            Yes   \n",
              "497   F   32             No        C      FORCE      No      M             No   \n",
              "498   M   13            Yes        C    STUDENT      No      S            Yes   \n",
              "499   F   19            Yes        M    STUDENT      No      S            Yes   \n",
              "\n",
              "    divorse Injury Spiritual_consult Insominia shizopherania vascula_demetia  \\\n",
              "0        No     No               Yes         N             P               P   \n",
              "1        No    Yes               Yes         P             P               P   \n",
              "2        No     No               Yes         P             P               P   \n",
              "3        No     No               Yes         P             P               N   \n",
              "4        No     No               Yes         P             P               P   \n",
              "..      ...    ...               ...       ...           ...             ...   \n",
              "495      No     No               Yes         P             N               P   \n",
              "496      No     No                No         P             P               N   \n",
              "497      No     No               Yes         N             P               P   \n",
              "498      No     No                No         N             P               N   \n",
              "499      No     No               Yes         N             P               P   \n",
              "\n",
              "    MBD Bipolar  agecode  \n",
              "0     P       N        1  \n",
              "1     N       N        1  \n",
              "2     N       P        1  \n",
              "3     N       P        2  \n",
              "4     P       P        1  \n",
              "..   ..     ...      ...  \n",
              "495   N       P        3  \n",
              "496   P       P        2  \n",
              "497   P       N        2  \n",
              "498   N       N        1  \n",
              "499   N       N        1  \n",
              "\n",
              "[500 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3559fe6f-7ab6-4d1d-aec7-2b92dfad2114\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>faNoily_status</th>\n",
              "      <th>religion</th>\n",
              "      <th>occupation</th>\n",
              "      <th>genetic</th>\n",
              "      <th>status</th>\n",
              "      <th>loss_of_parent</th>\n",
              "      <th>divorse</th>\n",
              "      <th>Injury</th>\n",
              "      <th>Spiritual_consult</th>\n",
              "      <th>Insominia</th>\n",
              "      <th>shizopherania</th>\n",
              "      <th>vascula_demetia</th>\n",
              "      <th>MBD</th>\n",
              "      <th>Bipolar</th>\n",
              "      <th>agecode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>18</td>\n",
              "      <td>Yes</td>\n",
              "      <td>C</td>\n",
              "      <td>STUDENT</td>\n",
              "      <td>Yes</td>\n",
              "      <td>S</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>F</td>\n",
              "      <td>30</td>\n",
              "      <td>Yes</td>\n",
              "      <td>M</td>\n",
              "      <td>ARTISAN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>S</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>22</td>\n",
              "      <td>Yes</td>\n",
              "      <td>C</td>\n",
              "      <td>STUDENT</td>\n",
              "      <td>No</td>\n",
              "      <td>S</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>35</td>\n",
              "      <td>No</td>\n",
              "      <td>M</td>\n",
              "      <td>ARTISAN</td>\n",
              "      <td>No</td>\n",
              "      <td>M</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>30</td>\n",
              "      <td>Yes</td>\n",
              "      <td>M</td>\n",
              "      <td>ARTISAN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>M</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>F</td>\n",
              "      <td>73</td>\n",
              "      <td>Yes</td>\n",
              "      <td>M</td>\n",
              "      <td>RETIRED</td>\n",
              "      <td>Yes</td>\n",
              "      <td>S</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>F</td>\n",
              "      <td>50</td>\n",
              "      <td>No</td>\n",
              "      <td>M</td>\n",
              "      <td>ARTISAN</td>\n",
              "      <td>No</td>\n",
              "      <td>M</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>F</td>\n",
              "      <td>32</td>\n",
              "      <td>No</td>\n",
              "      <td>C</td>\n",
              "      <td>FORCE</td>\n",
              "      <td>No</td>\n",
              "      <td>M</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>M</td>\n",
              "      <td>13</td>\n",
              "      <td>Yes</td>\n",
              "      <td>C</td>\n",
              "      <td>STUDENT</td>\n",
              "      <td>No</td>\n",
              "      <td>S</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>F</td>\n",
              "      <td>19</td>\n",
              "      <td>Yes</td>\n",
              "      <td>M</td>\n",
              "      <td>STUDENT</td>\n",
              "      <td>No</td>\n",
              "      <td>S</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 17 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3559fe6f-7ab6-4d1d-aec7-2b92dfad2114')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3559fe6f-7ab6-4d1d-aec7-2b92dfad2114 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3559fe6f-7ab6-4d1d-aec7-2b92dfad2114');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART 4: Label encode the CSV data.\n",
        "Now that we have the basics importeed into the Collabatory Notebook, we now need to encode the values, as Machine Leanring Models cannot typically handle Strings/Characters for input.\n",
        "\n",
        "To do this, we will utilize sklearns LabelEncoder, as this allows us to easily convert basic values, like Yes and No, to simple binary values.\n",
        "\n",
        "These values will first be transformed, and then we will drop the original column from the Pandas Dataframe that represents our dataset.\n",
        "\n",
        "After the original column is dropped, the new column that represents the encoded values is added to the dataframe with the same name."
      ],
      "metadata": {
        "id": "Hg7_Io3naoCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\"\"\"Create the Label Encoder\"\"\"\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "\"\"\"Convert Sex values (M/F) to binary values\"\"\"\n",
        "sex_label = label_encoder.fit_transform(df[\"sex\"])\n",
        "Data = df.drop(\"sex\", axis='columns')\n",
        "Data[\"sex\"] = sex_label\n",
        "\n",
        "\"\"\"Convert faNoily_status column (Yes/No) to binary values\"\"\"\n",
        "family_status = label_encoder.fit_transform(Data[\"faNoily_status\"])\n",
        "Data2 = Data.drop(\"faNoily_status\", axis='columns')\n",
        "Data2[\"family_status\"] = family_status\n",
        "\n",
        "\"\"\"Convert genetic column (Yes/No) to binary values\"\"\"\n",
        "genetic_status = label_encoder.fit_transform(Data2[\"genetic\"])\n",
        "Data3 = Data2.drop(\"genetic\", axis='columns')\n",
        "Data3[\"genetic\"] = genetic_status\n",
        "\n",
        "\"\"\"Convert status column (S/M) to binary values\"\"\"\n",
        "status = label_encoder.fit_transform(Data3[\"status\"])\n",
        "Data3 = Data3.drop(\"status\", axis='columns')\n",
        "Data3[\"status\"] = status\n",
        "\n",
        "\"\"\"Loss of Parent\"\"\"\n",
        "loss_of_parent = label_encoder.fit_transform(Data3[\"loss_of_parent\"])\n",
        "Data4 = Data3.drop(\"loss_of_parent\", axis='columns')\n",
        "Data4[\"loss_of_parent\"] = loss_of_parent\n",
        "\n",
        "\"\"\"Divorce\"\"\"\n",
        "divorce = label_encoder.fit_transform(Data4[\"divorse\"])\n",
        "Data5 = Data4.drop(\"divorse\", axis='columns')\n",
        "Data5[\"divorce\"] = divorce\n",
        "\n",
        "\"\"\"Injury\"\"\"\n",
        "injury = label_encoder.fit_transform(Data5[\"Injury\"])\n",
        "Data6 = Data5.drop(\"Injury\", axis='columns')\n",
        "Data6[\"Injury\"] = injury\n",
        "\n",
        "\"\"\"Spiritual Consult\"\"\"\n",
        "spiritual_consult = label_encoder.fit_transform(Data6[\"Spiritual_consult\"])\n",
        "Data7 = Data6.drop(\"Spiritual_consult\", axis='columns')\n",
        "Data7[\"Spiritual_consult\"] = spiritual_consult\n"
      ],
      "metadata": {
        "id": "rogOv82ybzBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the basic columns have been converted, the more complex rows with multiple values (such as religion, occupation, etc) now need to be encoded one-hot encoding using panda's get_dummies method. The get_dummies function converts every unique values into separate columns with binary values. For example, the religion column has 3 unique values 'C', 'M', 'O', so it converts into three columns called religion_C, religion_M, religion_O which each has binary values. Numeric encoding is not useful for values that no relation with each others. We have used feature name as prefix for these conversions. "
      ],
      "metadata": {
        "id": "bHARW4xvj9Mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"religion\"\"\"\n",
        "one_hot = pd.get_dummies(Data7['religion'], prefix='religion')\n",
        "Data8 = Data7.drop(\"religion\", axis='columns')\n",
        "Data8 = Data8.join(one_hot)\n",
        "\n",
        "one_hot = pd.get_dummies(Data8['occupation'], prefix='occupation')\n",
        "Data9 = Data8.drop(\"occupation\", axis='columns')\n",
        "Data9 = Data9.join(one_hot)\n",
        "\n",
        "one_hot = pd.get_dummies(Data9['agecode'], prefix='agecode')\n",
        "Data9 = Data9.drop(\"agecode\", axis='columns')\n",
        "Data9 = Data9.join(one_hot)\n",
        "\n",
        "Data9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "gJUmaswrj8h-",
        "outputId": "a2aff700-a8ae-4b95-95b0-1fb850dac3c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     age Insominia shizopherania vascula_demetia MBD Bipolar  sex  \\\n",
              "0     18         N             P               P   P       N    1   \n",
              "1     30         P             P               P   N       N    0   \n",
              "2     22         P             P               P   N       P    1   \n",
              "3     35         P             P               N   N       P    1   \n",
              "4     30         P             P               P   P       P    1   \n",
              "..   ...       ...           ...             ...  ..     ...  ...   \n",
              "495   73         P             N               P   N       P    0   \n",
              "496   50         P             P               N   P       P    0   \n",
              "497   32         N             P               P   P       N    0   \n",
              "498   13         N             P               N   N       N    1   \n",
              "499   19         N             P               P   N       N    0   \n",
              "\n",
              "     family_status  genetic  status  ...  religion_O  occupation_ARTISAN  \\\n",
              "0                1        1       1  ...           0                   0   \n",
              "1                1        1       1  ...           0                   1   \n",
              "2                1        0       1  ...           0                   0   \n",
              "3                0        0       0  ...           0                   1   \n",
              "4                1        1       0  ...           0                   1   \n",
              "..             ...      ...     ...  ...         ...                 ...   \n",
              "495              1        1       1  ...           0                   0   \n",
              "496              0        0       0  ...           0                   1   \n",
              "497              0        0       0  ...           0                   0   \n",
              "498              1        0       1  ...           0                   0   \n",
              "499              1        0       1  ...           0                   0   \n",
              "\n",
              "     occupation_C/SERVANT  occupation_FORCE  occupation_RETIRED  \\\n",
              "0                       0                 0                   0   \n",
              "1                       0                 0                   0   \n",
              "2                       0                 0                   0   \n",
              "3                       0                 0                   0   \n",
              "4                       0                 0                   0   \n",
              "..                    ...               ...                 ...   \n",
              "495                     0                 0                   1   \n",
              "496                     0                 0                   0   \n",
              "497                     0                 1                   0   \n",
              "498                     0                 0                   0   \n",
              "499                     0                 0                   0   \n",
              "\n",
              "     occupation_STUDENT  occupation_UNEMPLYD  agecode_1  agecode_2  agecode_3  \n",
              "0                     1                    0          1          0          0  \n",
              "1                     0                    0          1          0          0  \n",
              "2                     1                    0          1          0          0  \n",
              "3                     0                    0          0          1          0  \n",
              "4                     0                    0          1          0          0  \n",
              "..                  ...                  ...        ...        ...        ...  \n",
              "495                   0                    0          0          0          1  \n",
              "496                   0                    0          0          1          0  \n",
              "497                   0                    0          0          1          0  \n",
              "498                   1                    0          1          0          0  \n",
              "499                   1                    0          1          0          0  \n",
              "\n",
              "[500 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9efce314-7c0c-4f6e-8b56-af7dbaa00051\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>Insominia</th>\n",
              "      <th>shizopherania</th>\n",
              "      <th>vascula_demetia</th>\n",
              "      <th>MBD</th>\n",
              "      <th>Bipolar</th>\n",
              "      <th>sex</th>\n",
              "      <th>family_status</th>\n",
              "      <th>genetic</th>\n",
              "      <th>status</th>\n",
              "      <th>...</th>\n",
              "      <th>religion_O</th>\n",
              "      <th>occupation_ARTISAN</th>\n",
              "      <th>occupation_C/SERVANT</th>\n",
              "      <th>occupation_FORCE</th>\n",
              "      <th>occupation_RETIRED</th>\n",
              "      <th>occupation_STUDENT</th>\n",
              "      <th>occupation_UNEMPLYD</th>\n",
              "      <th>agecode_1</th>\n",
              "      <th>agecode_2</th>\n",
              "      <th>agecode_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>73</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>50</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>32</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>13</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>19</td>\n",
              "      <td>N</td>\n",
              "      <td>P</td>\n",
              "      <td>P</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9efce314-7c0c-4f6e-8b56-af7dbaa00051')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9efce314-7c0c-4f6e-8b56-af7dbaa00051 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9efce314-7c0c-4f6e-8b56-af7dbaa00051');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that Y columns have been converted, some has multiple values, for example for the vascula demetia, it has 4 values:  'N', 'N       \u001a­>', 'P', 'P       \u001c­>'. We cleaned up those unicode characters and kept the only values N and P. After cleaning up the unicode characters, the five dependent variables (target values) are converted into binary using the label_encoder. \n",
        "\n",
        "Additionally, in later sections of this study, we are wanting to predict multiple labels at the same time. Generally, we can just pull out all of the columns that we want to use at runtime and pass them into Y, but in our specific use case this is not possible due to SMOTE not supporting multi-class values of Y.\n",
        "\n",
        "Because of this limitation, the original study concatenates all five target (dependent variables) into a single string and places it into a singlular column called \"target\". \n",
        "\n",
        "In order to remove rare combinations, and to improve accuracy, the original study removes any 'target' (string value that represents the five dependent variables) that do not occur more than 6 times. \n",
        "\n",
        "This data is then later used for the Multi-Label Neural Network and comparing it to Classical Machine Learning models. \n",
        "\n",
        "Additionally, the data is then split into multiple dataframes called data, data_orig, data2, data_feat, and data3. An explanation of each is below.\n",
        "\n",
        "```\n",
        "data/data_orig: Dataframe that contains the individual dependent variables, does not contain target. Used for testing the Single-label Neural Network.\n",
        "\n",
        "data2/data3/data_feat: Dataframe that has removed the individual dependent variable and combined them into one column called 'target'. Used for the multi-label Neural Network.\n",
        "```"
      ],
      "metadata": {
        "id": "tKsHjNyWODpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Insominia N|P\n",
        "insominia = label_encoder.fit_transform(Data9[\"Insominia\"])\n",
        "data = Data9.drop(\"Insominia\", axis='columns')\n",
        "data[\"Insominia\"] = insominia\n",
        "\n",
        "#shizopherania N|P\n",
        "shizopherania = label_encoder.fit_transform(data[\"shizopherania\"])\n",
        "data = data.drop(\"shizopherania\", axis='columns')\n",
        "data[\"shizopherania\"] = shizopherania\n",
        "\n",
        "#vascula demetia N|P\n",
        "vascula_demetia = label_encoder.fit_transform(data[\"vascula_demetia\"])\n",
        "data = data.drop(\"vascula_demetia\", axis='columns')\n",
        "data[\"vascula_demetia\"] = vascula_demetia\n",
        "\n",
        "#MBD N|P\n",
        "MBD = label_encoder.fit_transform(Data9[\"MBD\"])\n",
        "data = data.drop(\"MBD\", axis='columns')\n",
        "data[\"MBD\"] = MBD\n",
        "\n",
        "#Bipolar N|P\n",
        "Bipolar = label_encoder.fit_transform(Data9[\"Bipolar\"])\n",
        "data = data.drop(\"Bipolar\", axis='columns')\n",
        "data[\"Bipolar\"] = Bipolar\n",
        "\n",
        "data_orig = data.copy()\n",
        "data_feat = data.copy()\n",
        "del data_feat['Insominia']\n",
        "del data_feat['shizopherania']\n",
        "del data_feat['vascula_demetia']\n",
        "del data_feat['MBD']\n",
        "del data_feat['Bipolar']\n",
        "\n",
        "# Concatenate 5 target features into 1 single column\n",
        "data['target']=data['Insominia'].astype(str)+data['shizopherania'].astype(str)+data['vascula_demetia'].astype(str)+data['MBD'].astype(str)+data['Bipolar'].astype(str)\n",
        "\n",
        "# Exclude the combinations that occurs less than 6 to make good balancing before use SMOTE algorithm. \n",
        "data = data.groupby('target').filter(lambda x: len(x) > 6)\n",
        "\n",
        "data3 = data.copy()\n",
        "\n",
        "data2 = data.copy()\n",
        "\n",
        "del data['target']\n",
        "\n",
        "\n",
        "# remove these values since they are now represented by 'target'\n",
        "del data2['Insominia']\n",
        "del data2['shizopherania']\n",
        "del data2['vascula_demetia']\n",
        "del data2['MBD']\n",
        "del data2['Bipolar']\n",
        "\n",
        "\n",
        "data2"
      ],
      "metadata": {
        "id": "P4z4esluOv2E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "5f417113-3deb-435f-cf5d-69ab627af17c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     age  sex  family_status  genetic  status  loss_of_parent  divorce  \\\n",
              "0     18    1              1        1       1               1        0   \n",
              "2     22    1              1        0       1               0        0   \n",
              "3     35    1              0        0       0               0        0   \n",
              "4     30    1              1        1       0               0        0   \n",
              "5     86    0              1        0       0               1        0   \n",
              "..   ...  ...            ...      ...     ...             ...      ...   \n",
              "495   73    0              1        1       1               1        0   \n",
              "496   50    0              0        0       0               1        0   \n",
              "497   32    0              0        0       0               0        0   \n",
              "498   13    1              1        0       1               1        0   \n",
              "499   19    0              1        0       1               1        0   \n",
              "\n",
              "     Injury  Spiritual_consult  religion_C  ...  occupation_ARTISAN  \\\n",
              "0         0                  1           1  ...                   0   \n",
              "2         0                  1           1  ...                   0   \n",
              "3         0                  1           0  ...                   1   \n",
              "4         0                  1           0  ...                   1   \n",
              "5         0                  1           1  ...                   0   \n",
              "..      ...                ...         ...  ...                 ...   \n",
              "495       0                  1           0  ...                   0   \n",
              "496       0                  0           0  ...                   1   \n",
              "497       0                  1           1  ...                   0   \n",
              "498       0                  0           1  ...                   0   \n",
              "499       0                  1           0  ...                   0   \n",
              "\n",
              "     occupation_C/SERVANT  occupation_FORCE  occupation_RETIRED  \\\n",
              "0                       0                 0                   0   \n",
              "2                       0                 0                   0   \n",
              "3                       0                 0                   0   \n",
              "4                       0                 0                   0   \n",
              "5                       0                 0                   1   \n",
              "..                    ...               ...                 ...   \n",
              "495                     0                 0                   1   \n",
              "496                     0                 0                   0   \n",
              "497                     0                 1                   0   \n",
              "498                     0                 0                   0   \n",
              "499                     0                 0                   0   \n",
              "\n",
              "     occupation_STUDENT  occupation_UNEMPLYD  agecode_1  agecode_2  agecode_3  \\\n",
              "0                     1                    0          1          0          0   \n",
              "2                     1                    0          1          0          0   \n",
              "3                     0                    0          0          1          0   \n",
              "4                     0                    0          1          0          0   \n",
              "5                     0                    0          0          0          1   \n",
              "..                  ...                  ...        ...        ...        ...   \n",
              "495                   0                    0          0          0          1   \n",
              "496                   0                    0          0          1          0   \n",
              "497                   0                    0          0          1          0   \n",
              "498                   1                    0          1          0          0   \n",
              "499                   1                    0          1          0          0   \n",
              "\n",
              "     target  \n",
              "0     01110  \n",
              "2     11101  \n",
              "3     11001  \n",
              "4     11111  \n",
              "5     01100  \n",
              "..      ...  \n",
              "495   10101  \n",
              "496   11011  \n",
              "497   01110  \n",
              "498   01000  \n",
              "499   01100  \n",
              "\n",
              "[484 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75f93275-5445-4b50-a169-8f69815a5c2f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>family_status</th>\n",
              "      <th>genetic</th>\n",
              "      <th>status</th>\n",
              "      <th>loss_of_parent</th>\n",
              "      <th>divorce</th>\n",
              "      <th>Injury</th>\n",
              "      <th>Spiritual_consult</th>\n",
              "      <th>religion_C</th>\n",
              "      <th>...</th>\n",
              "      <th>occupation_ARTISAN</th>\n",
              "      <th>occupation_C/SERVANT</th>\n",
              "      <th>occupation_FORCE</th>\n",
              "      <th>occupation_RETIRED</th>\n",
              "      <th>occupation_STUDENT</th>\n",
              "      <th>occupation_UNEMPLYD</th>\n",
              "      <th>agecode_1</th>\n",
              "      <th>agecode_2</th>\n",
              "      <th>agecode_3</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>01110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>86</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>01100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>01110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>01000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>01100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>484 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75f93275-5445-4b50-a169-8f69815a5c2f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75f93275-5445-4b50-a169-8f69815a5c2f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75f93275-5445-4b50-a169-8f69815a5c2f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PART 5: Create Test/Training Set from Data\n",
        "Now that we have properly encoded our dataset, we will give an example of how to split the dataset using sklearns train_test_split library. \n",
        "\n",
        "In the example below, we are taking out Insomnia as our Y value (value that we want to predict) while splitting the dataset into the respective test and training set. A important note is that we are explictly specifying that the test set is 30% of the values, and the training set is 70% of the values. This is set to this specific ratio in order to best replicate what was done in the original study. "
      ],
      "metadata": {
        "id": "DC9nF6dAlbOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "y = data.pop('Insominia')\n",
        "X = data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "X_train"
      ],
      "metadata": {
        "id": "inVe7Kk6li7-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "962e4e9d-494a-4d5d-c08b-a2c78d1d7e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     age  sex  family_status  genetic  status  loss_of_parent  divorce  \\\n",
              "6     68    1              0        0       0               1        0   \n",
              "133   19    0              1        0       1               1        0   \n",
              "304   19    1              0        1       1               0        0   \n",
              "380   21    0              0        0       1               1        0   \n",
              "335   56    0              0        0       0               1        1   \n",
              "..   ...  ...            ...      ...     ...             ...      ...   \n",
              "321   32    1              1        0       1               1        0   \n",
              "186   40    0              0        0       0               0        1   \n",
              "369   34    1              1        1       0               1        0   \n",
              "400   43    0              0        0       0               1        0   \n",
              "410   21    0              1        1       1               1        0   \n",
              "\n",
              "     Injury  Spiritual_consult  religion_C  ...  occupation_RETIRED  \\\n",
              "6         0                  1           0  ...                   1   \n",
              "133       0                  1           0  ...                   0   \n",
              "304       0                  1           0  ...                   0   \n",
              "380       0                  1           1  ...                   0   \n",
              "335       1                  1           0  ...                   0   \n",
              "..      ...                ...         ...  ...                 ...   \n",
              "321       0                  1           0  ...                   0   \n",
              "186       0                  0           1  ...                   0   \n",
              "369       0                  1           0  ...                   0   \n",
              "400       0                  0           1  ...                   0   \n",
              "410       0                  0           1  ...                   0   \n",
              "\n",
              "     occupation_STUDENT  occupation_UNEMPLYD  agecode_1  agecode_2  agecode_3  \\\n",
              "6                     0                    0          0          0          1   \n",
              "133                   0                    0          1          0          0   \n",
              "304                   1                    0          1          0          0   \n",
              "380                   1                    0          1          0          0   \n",
              "335                   0                    0          0          0          1   \n",
              "..                  ...                  ...        ...        ...        ...   \n",
              "321                   0                    0          0          1          0   \n",
              "186                   0                    1          0          1          0   \n",
              "369                   0                    0          0          1          0   \n",
              "400                   0                    0          0          1          0   \n",
              "410                   1                    0          1          0          0   \n",
              "\n",
              "     shizopherania  vascula_demetia  MBD  Bipolar  \n",
              "6                1                1    1        1  \n",
              "133              1                1    1        1  \n",
              "304              1                1    0        0  \n",
              "380              1                1    0        0  \n",
              "335              1                1    0        1  \n",
              "..             ...              ...  ...      ...  \n",
              "321              1                1    1        0  \n",
              "186              1                1    0        1  \n",
              "369              1                1    0        0  \n",
              "400              1                0    0        0  \n",
              "410              1                0    1        0  \n",
              "\n",
              "[338 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0959291-4def-42c0-8a52-673023756147\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>family_status</th>\n",
              "      <th>genetic</th>\n",
              "      <th>status</th>\n",
              "      <th>loss_of_parent</th>\n",
              "      <th>divorce</th>\n",
              "      <th>Injury</th>\n",
              "      <th>Spiritual_consult</th>\n",
              "      <th>religion_C</th>\n",
              "      <th>...</th>\n",
              "      <th>occupation_RETIRED</th>\n",
              "      <th>occupation_STUDENT</th>\n",
              "      <th>occupation_UNEMPLYD</th>\n",
              "      <th>agecode_1</th>\n",
              "      <th>agecode_2</th>\n",
              "      <th>agecode_3</th>\n",
              "      <th>shizopherania</th>\n",
              "      <th>vascula_demetia</th>\n",
              "      <th>MBD</th>\n",
              "      <th>Bipolar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>68</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335</th>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400</th>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>338 rows × 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0959291-4def-42c0-8a52-673023756147')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c0959291-4def-42c0-8a52-673023756147 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c0959291-4def-42c0-8a52-673023756147');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To better understand why we are balancing the dataset using SMOTE, lets take a look at the ratio of the respective values in the Insomnia column."
      ],
      "metadata": {
        "id": "N2ZBXinY8lIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Insominia'].value_counts()/len(df)"
      ],
      "metadata": {
        "id": "eVVMlOOihdCC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1beb39ff-cc4d-4f06-df87-4a35cb40e858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "N    0.594\n",
              "P    0.406\n",
              "Name: Insominia, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, there is a significant larger amount of N values (Negative) compared to P values (positive). In an ideal dataset, we want to have the same number of N samples and P samples, as this will prevent our Machine Learning models from just guessing N due to the larger ratio of N value versus P values."
      ],
      "metadata": {
        "id": "8FG6QecKHnpv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PART 6: Balance Insomnia dataset with SMOTE\n",
        "The following is an example of how we will be using the SMOTE algorithm in the future to split the data, and what the overall dataset will look after it is properly balanced. The new dataset will now have 400 samples, because this is the number of total samples required so that there will be an equivilant ratio between all of dependent values in this dataset.\n"
      ],
      "metadata": {
        "id": "DC80aaF4gM_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: How many random samples do we need?\n",
        "smote = SMOTE(random_state=101)\n",
        "X_train_new, y_train_new = smote.fit_resample(X_train, y_train.ravel())\n",
        "X_train_new"
      ],
      "metadata": {
        "id": "2aq7Dhk_WnqW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "95dc0e10-7c13-47ea-84ff-9745a1e12219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     age  sex  family_status  genetic  status  loss_of_parent  divorce  \\\n",
              "0     68    1              0        0       0               1        0   \n",
              "1     19    0              1        0       1               1        0   \n",
              "2     19    1              0        1       1               0        0   \n",
              "3     21    0              0        0       1               1        0   \n",
              "4     56    0              0        0       0               1        1   \n",
              "..   ...  ...            ...      ...     ...             ...      ...   \n",
              "397   55    0              0        0       0               0        0   \n",
              "398   34    0              1        0       0               0        0   \n",
              "399   56    0              0        0       0               1        0   \n",
              "400   56    0              0        0       0               1        0   \n",
              "401   54    0              0        0       0               0        0   \n",
              "\n",
              "     Injury  Spiritual_consult  religion_C  ...  occupation_RETIRED  \\\n",
              "0         0                  1           0  ...                   1   \n",
              "1         0                  1           0  ...                   0   \n",
              "2         0                  1           0  ...                   0   \n",
              "3         0                  1           1  ...                   0   \n",
              "4         1                  1           0  ...                   0   \n",
              "..      ...                ...         ...  ...                 ...   \n",
              "397       0                  1           1  ...                   0   \n",
              "398       0                  0           0  ...                   0   \n",
              "399       0                  1           0  ...                   0   \n",
              "400       0                  1           0  ...                   0   \n",
              "401       0                  1           0  ...                   0   \n",
              "\n",
              "     occupation_STUDENT  occupation_UNEMPLYD  agecode_1  agecode_2  agecode_3  \\\n",
              "0                     0                    0          0          0          1   \n",
              "1                     0                    0          1          0          0   \n",
              "2                     1                    0          1          0          0   \n",
              "3                     1                    0          1          0          0   \n",
              "4                     0                    0          0          0          1   \n",
              "..                  ...                  ...        ...        ...        ...   \n",
              "397                   0                    0          0          0          1   \n",
              "398                   0                    1          0          1          0   \n",
              "399                   0                    0          0          0          1   \n",
              "400                   0                    0          0          0          1   \n",
              "401                   0                    0          0          0          1   \n",
              "\n",
              "     shizopherania  vascula_demetia  MBD  Bipolar  \n",
              "0                1                1    1        1  \n",
              "1                1                1    1        1  \n",
              "2                1                1    0        0  \n",
              "3                1                1    0        0  \n",
              "4                1                1    0        1  \n",
              "..             ...              ...  ...      ...  \n",
              "397              0                1    0        1  \n",
              "398              1                1    1        1  \n",
              "399              1                1    0        1  \n",
              "400              1                1    0        1  \n",
              "401              0                1    0        1  \n",
              "\n",
              "[402 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48686099-5a9c-441f-9194-f3f91c930b50\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>family_status</th>\n",
              "      <th>genetic</th>\n",
              "      <th>status</th>\n",
              "      <th>loss_of_parent</th>\n",
              "      <th>divorce</th>\n",
              "      <th>Injury</th>\n",
              "      <th>Spiritual_consult</th>\n",
              "      <th>religion_C</th>\n",
              "      <th>...</th>\n",
              "      <th>occupation_RETIRED</th>\n",
              "      <th>occupation_STUDENT</th>\n",
              "      <th>occupation_UNEMPLYD</th>\n",
              "      <th>agecode_1</th>\n",
              "      <th>agecode_2</th>\n",
              "      <th>agecode_3</th>\n",
              "      <th>shizopherania</th>\n",
              "      <th>vascula_demetia</th>\n",
              "      <th>MBD</th>\n",
              "      <th>Bipolar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>68</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400</th>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401</th>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>402 rows × 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48686099-5a9c-441f-9194-f3f91c930b50')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48686099-5a9c-441f-9194-f3f91c930b50 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48686099-5a9c-441f-9194-f3f91c930b50');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PART 7: Multi-Label Classification with non-balanced data using Classic ML models\n",
        "In this section, we begin to evaluate the original study by running the standard machine learning algorithms on non-balanced datasets to check their accuracy values. This is done by splitting the dataset into a training and testing set. Since the original study used MLP, Support Vector Machine (SVM), RandomForest, and DecisionTree, we are using the same Machine Learning models.\n",
        "\n",
        "In this part, the models are first trained with the training set and then evaluated with the test set, and then their accuracy values are outputted. These are the accuracy values for the Multi-Label unbalanced data. The best one of these algorithms will then be selected to compare aganist the Multi-Label Neural Network that will be tested in part 9. \n",
        "\n",
        "In our testing, on average, MLP was the most accurate algorihtm. With that being said, your results may vary as it did not find MLP to be the most accurate on every single run."
      ],
      "metadata": {
        "id": "-EW18enp2kCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_temp = data2.copy()\n",
        "y_5 = data_temp.pop('target')\n",
        "X_5 = data_temp\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_5, y_5, test_size=0.2)\n",
        "\n",
        "result_table = []\n",
        "MLP = MLPClassifier(alpha=1, max_iter=1000)\n",
        "MLP.fit(X_train, y_train)\n",
        "score_MLP = MLP.score(X_test, y_test)\n",
        "print(\"MLP: \", score_MLP)\n",
        "result_table.append(f'MLP,Non-Balanced,{score_MLP}')\n",
        "\n",
        "svc = LinearSVC(C=0.025, max_iter=10000)\n",
        "svc.fit(X_train, y_train)\n",
        "score_svm = svc.score(X_test, y_test)\n",
        "print(\"SVM: \", score_svm)\n",
        "result_table.append(f'SVM,Non-Balanced,{score_svm}')\n",
        "\n",
        "#RF = RandomForestClassifier(max_depth=5, n_estimators=100, max_features=1)\n",
        "RF = RandomForestClassifier(max_depth=5, n_estimators=100)\n",
        "RF.fit(X_train, y_train)\n",
        "score_RF = RF.score(X_test, y_test)\n",
        "print(\"RandomForest: \", score_RF)\n",
        "result_table.append(f'RandomForest,Non-Balanced,{score_RF}')\n",
        "\n",
        "decistion_tree = DecisionTreeClassifier(max_depth=5)\n",
        "decistion_tree.fit(X_train, y_train)\n",
        "score_decistion_tree = decistion_tree.score(X_test, y_test)\n",
        "print(\"DecitionTree: \", score_decistion_tree)\n",
        "result_table.append(f'DecisionTree,Non-Balanced,{score_decistion_tree}')\n"
      ],
      "metadata": {
        "id": "NUUNsFY1evoR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f6e50d-b0c8-4ab4-8e51-9d0d9c01717e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP:  0.3711340206185567\n",
            "SVM:  0.3711340206185567\n",
            "RandomForest:  0.4020618556701031\n",
            "DecitionTree:  0.4020618556701031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PART 8: Multi-Label Classification with balanced data using Classic ML models\n",
        "This part is very similar to Part 7, but we are now using Balanced Data inside of the classical Machine Learning models instead of unbalanced data. The best model from this section will be compared aganist the Multi-Label Neural Network from Part 12. \n",
        "\n",
        "In our testing, on average, the Random Forest model is generally the most accurate. With that being said, your results may vary as in our testing, Random Forest was not the most accurate on every single run. \n"
      ],
      "metadata": {
        "id": "fxdI3_xT2pab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_temp = data2.copy()\n",
        "#print(data2)\n",
        "y_6 = data_temp.pop('target')\n",
        "X_6 = data_temp\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_6, y_6, test_size=0.2)\n",
        "\n",
        "\"\"\"TODO: Fix smote here\"\"\"\n",
        "smote = SMOTE(random_state=101)\n",
        "X_train_new, y_train_new = smote.fit_resample(X_train, y_train.ravel())\n",
        "\n",
        "MLP = MLPClassifier(alpha=1, max_iter=1000)\n",
        "MLP.fit(X_train_new, y_train_new)\n",
        "score_MLP = MLP.score(X_test, y_test)\n",
        "print(f\"MLP score is : \", score_MLP)\n",
        "result_table.append(f'MLP,Balanced,{score_MLP}')\n",
        "\n",
        "svc = LinearSVC(C=0.025, max_iter=10000)\n",
        "svc.fit(X_train_new, y_train_new)\n",
        "score_svm = svc.score(X_test, y_test)\n",
        "print(f\"SVM score is: \", score_svm)\n",
        "result_table.append(f'SVM,Balanced,{score_svm}')\n",
        "\n",
        "#RF = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
        "RF = RandomForestClassifier(max_depth=5, n_estimators=100)\n",
        "RF.fit(X_train_new, y_train_new)\n",
        "score_RF = RF.score(X_test, y_test)\n",
        "print(f\"RandomForest score is: \", score_RF)\n",
        "result_table.append(f'RandomForest,Balanced,{score_RF}')\n",
        "\n",
        "decistion_tree = DecisionTreeClassifier(max_depth=5)\n",
        "decistion_tree.fit(X_train_new, y_train_new)\n",
        "score_decistion_tree = decistion_tree.score(X_test, y_test)\n",
        "print(\"DecitionTree score is: \", score_decistion_tree)\n",
        "result_table.append(f'DecisionTree,Balanced,{score_decistion_tree}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyfME62cmR5m",
        "outputId": "10c09102-1ec3-4ed6-e088-db378ad3c4b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP score is :  0.35051546391752575\n",
            "SVM score is:  0.36082474226804123\n",
            "RandomForest score is:  0.3711340206185567\n",
            "DecitionTree score is:  0.35051546391752575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PART 9: Single Label Classificaiton Neural Network With unbalanced data\n",
        "In this part we build/evaluate the Single Label Neural Network that is mentioned in the original study. In this case, we do not use target, since we are wanting the accuracy of only ONE dependent variable, not all five. \n",
        "\n",
        "The Neural Network model is defined in the function called NeuralNetwork_A, and our code will call on this function and pass it the specific dependent variable (target PDD) value one by one into a new Model, where it is then fit with the training samples and tested with the validation/test data. \n"
      ],
      "metadata": {
        "id": "2jayhHNt2E_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Dense,Input,Dropout,Flatten,Conv2D,MaxPool2D\n",
        "\n",
        "target_names = ['Insominia', 'shizopherania', 'vascula_demetia', 'MBD', 'Bipolar']\n",
        "\n",
        "def NeuralNetwork_A(X, y):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "  X_train_test, X_validation, y_train_test, y_validation = train_test_split(X_train, y_train, test_size=0.3)\n",
        "\n",
        "\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(15, input_dim=25, activation='relu', name='Input'))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(20, activation='relu', name='Hidden1'))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(40, activation='relu', name='Hidden2'))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(50, activation='relu', name='Hidden3'))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(1, activation='sigmoid', name='Output'))\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  X_train_np = np.asarray(X_train_test).astype('int')\n",
        "\n",
        "  X_train_tensor = tf.convert_to_tensor(X_train_np)\n",
        "  y_train_tensor = tf.convert_to_tensor(y_train_test)\n",
        "\n",
        "  #print(X_train_tensor.shape)\n",
        "  #print(y_train_tensor.shape)\n",
        "\n",
        "  model.fit(X_train_tensor, y_train_tensor, epochs=40, batch_size=10)\n",
        "\n",
        "\n",
        "  # evaluate the model with the validation data\n",
        "  X_validate_np = np.asarray(X_validation).astype('int')\n",
        "\n",
        "  X_validate_tensor = tf.convert_to_tensor(X_validate_np)\n",
        "  y_validate_tensor = tf.convert_to_tensor(y_validation)\n",
        "\n",
        "  r_val = model.evaluate(X_validate_tensor, y_validate_tensor, batch_size=10)\n",
        "\n",
        "  #evaluate the model with test data\n",
        "  X_test_np = np.asarray(X_test).astype('int')\n",
        "\n",
        "  X_test_tensor = tf.convert_to_tensor(X_test_np)\n",
        "  y_test_tensor = tf.convert_to_tensor(y_test)\n",
        "\n",
        "  r_test = model.evaluate(X_test_tensor, y_test_tensor, batch_size=10)\n",
        "\n",
        "  return r_val, r_test\n",
        "\n",
        "def prep_data(X, target):\n",
        "  y = X.pop(target)\n",
        "  return X, y\n",
        "\n",
        "results1 = []\n",
        "result_table2 = []\n",
        "for t in target_names:\n",
        "  x_i = data_orig.copy()\n",
        "  x_i, y_i = prep_data(x_i, t)\n",
        "  r_val, r_test = NeuralNetwork_A(x_i, y_i)\n",
        "  results1.append(f\"{t} - Validation loss & accuracy: {r_val}\")\n",
        "  results1.append(f\"{t} - Test loss & accuracy: {r_test}\")\n",
        "  result_table2.append(f'{t},Non-Balanced,Validation,{r_val[1]}')\n",
        "  result_table2.append(f'{t},Non-Balanced,Test,{r_test[1]}')\n",
        "\n",
        "for r in results1:\n",
        "  print(r)\n"
      ],
      "metadata": {
        "id": "UWQHQqVuDqW3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc8c7fc9-eb44-4578-cfc4-aa55b8fa0b80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 1.7525 - accuracy: 0.4643\n",
            "Epoch 2/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 1.3733 - accuracy: 0.4929\n",
            "Epoch 3/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 1.0810 - accuracy: 0.4750\n",
            "Epoch 4/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.0914 - accuracy: 0.5036\n",
            "Epoch 5/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.9424 - accuracy: 0.5143\n",
            "Epoch 6/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.8722 - accuracy: 0.5179\n",
            "Epoch 7/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.8649 - accuracy: 0.4929\n",
            "Epoch 8/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.8703 - accuracy: 0.5357\n",
            "Epoch 9/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.8066 - accuracy: 0.5321\n",
            "Epoch 10/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.7811 - accuracy: 0.4714\n",
            "Epoch 11/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.7728 - accuracy: 0.5607\n",
            "Epoch 12/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7861 - accuracy: 0.5500\n",
            "Epoch 13/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.5464\n",
            "Epoch 14/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7119 - accuracy: 0.5571\n",
            "Epoch 15/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7226 - accuracy: 0.5786\n",
            "Epoch 16/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7362 - accuracy: 0.5714\n",
            "Epoch 17/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7451 - accuracy: 0.5643\n",
            "Epoch 18/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.7050 - accuracy: 0.5750\n",
            "Epoch 19/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6763 - accuracy: 0.6214\n",
            "Epoch 20/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6960 - accuracy: 0.6036\n",
            "Epoch 21/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.7274 - accuracy: 0.5429\n",
            "Epoch 22/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6802 - accuracy: 0.5929\n",
            "Epoch 23/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.7135 - accuracy: 0.5286\n",
            "Epoch 24/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.7098 - accuracy: 0.5250\n",
            "Epoch 25/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6760 - accuracy: 0.6321\n",
            "Epoch 26/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.7050 - accuracy: 0.6000\n",
            "Epoch 27/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6900 - accuracy: 0.6036\n",
            "Epoch 28/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6923 - accuracy: 0.5964\n",
            "Epoch 29/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6680 - accuracy: 0.5857\n",
            "Epoch 30/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6861 - accuracy: 0.6036\n",
            "Epoch 31/40\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.6780 - accuracy: 0.5893\n",
            "Epoch 32/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6821 - accuracy: 0.6071\n",
            "Epoch 33/40\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.6877 - accuracy: 0.5893\n",
            "Epoch 34/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6520 - accuracy: 0.6464\n",
            "Epoch 35/40\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.6812 - accuracy: 0.5679\n",
            "Epoch 36/40\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.6635 - accuracy: 0.6286\n",
            "Epoch 37/40\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.6834 - accuracy: 0.5857\n",
            "Epoch 38/40\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.6635 - accuracy: 0.5929\n",
            "Epoch 39/40\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6669 - accuracy: 0.6036\n",
            "Epoch 40/40\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.6645 - accuracy: 0.6250\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6725 - accuracy: 0.5917\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.6200\n",
            "Epoch 1/40\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 1.9470 - accuracy: 0.4786\n",
            "Epoch 2/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.0160 - accuracy: 0.7071\n",
            "Epoch 3/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.9721 - accuracy: 0.7143\n",
            "Epoch 4/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.7107\n",
            "Epoch 5/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.7100 - accuracy: 0.7643\n",
            "Epoch 6/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.7804 - accuracy: 0.7679\n",
            "Epoch 7/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.7397 - accuracy: 0.7500\n",
            "Epoch 8/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.8036\n",
            "Epoch 9/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.8286\n",
            "Epoch 10/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.8179\n",
            "Epoch 11/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6302 - accuracy: 0.8321\n",
            "Epoch 12/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.8321\n",
            "Epoch 13/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.8464\n",
            "Epoch 14/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.8500\n",
            "Epoch 15/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6059 - accuracy: 0.8286\n",
            "Epoch 16/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.8536\n",
            "Epoch 17/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.8286\n",
            "Epoch 18/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.8536\n",
            "Epoch 19/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.8286\n",
            "Epoch 20/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.8571\n",
            "Epoch 21/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.8607\n",
            "Epoch 22/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.8679\n",
            "Epoch 23/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5599 - accuracy: 0.8571\n",
            "Epoch 24/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.8643\n",
            "Epoch 25/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.8679\n",
            "Epoch 26/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.8714\n",
            "Epoch 27/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.8679\n",
            "Epoch 28/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.8607\n",
            "Epoch 29/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8643\n",
            "Epoch 30/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8750\n",
            "Epoch 31/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.8643\n",
            "Epoch 32/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.8643\n",
            "Epoch 33/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.8643\n",
            "Epoch 34/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.8571\n",
            "Epoch 35/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8679\n",
            "Epoch 36/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.8643\n",
            "Epoch 37/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.8571\n",
            "Epoch 38/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.8643\n",
            "Epoch 39/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.8643\n",
            "Epoch 40/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4107 - accuracy: 0.8643\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.8083\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8600\n",
            "Epoch 1/40\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 2.0707 - accuracy: 0.4429\n",
            "Epoch 2/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.3965 - accuracy: 0.5500\n",
            "Epoch 3/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 1.1207 - accuracy: 0.5071\n",
            "Epoch 4/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.0594 - accuracy: 0.5500\n",
            "Epoch 5/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.9363 - accuracy: 0.5786\n",
            "Epoch 6/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.8494 - accuracy: 0.5286\n",
            "Epoch 7/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7660 - accuracy: 0.5607\n",
            "Epoch 8/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.8287 - accuracy: 0.5607\n",
            "Epoch 9/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7693 - accuracy: 0.5714\n",
            "Epoch 10/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7843 - accuracy: 0.5607\n",
            "Epoch 11/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7020 - accuracy: 0.6179\n",
            "Epoch 12/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7104 - accuracy: 0.5321\n",
            "Epoch 13/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7218 - accuracy: 0.6036\n",
            "Epoch 14/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6874 - accuracy: 0.6429\n",
            "Epoch 15/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.6607\n",
            "Epoch 16/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7005 - accuracy: 0.6214\n",
            "Epoch 17/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6862 - accuracy: 0.6071\n",
            "Epoch 18/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7098 - accuracy: 0.6321\n",
            "Epoch 19/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.6071\n",
            "Epoch 20/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 0.6321\n",
            "Epoch 21/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6708 - accuracy: 0.6250\n",
            "Epoch 22/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.6357\n",
            "Epoch 23/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6563 - accuracy: 0.6321\n",
            "Epoch 24/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6519 - accuracy: 0.6500\n",
            "Epoch 25/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6409 - accuracy: 0.6607\n",
            "Epoch 26/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6767 - accuracy: 0.6536\n",
            "Epoch 27/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.6500\n",
            "Epoch 28/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.6500\n",
            "Epoch 29/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.6429\n",
            "Epoch 30/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6549 - accuracy: 0.6643\n",
            "Epoch 31/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.6536\n",
            "Epoch 32/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.6571\n",
            "Epoch 33/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6467 - accuracy: 0.6571\n",
            "Epoch 34/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.6643\n",
            "Epoch 35/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.6571\n",
            "Epoch 36/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.6643\n",
            "Epoch 37/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6571 - accuracy: 0.6571\n",
            "Epoch 38/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.6643\n",
            "Epoch 39/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.6643\n",
            "Epoch 40/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6462 - accuracy: 0.6607\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6009 - accuracy: 0.7500\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6263 - accuracy: 0.7000\n",
            "Epoch 1/40\n",
            "28/28 [==============================] - 1s 3ms/step - loss: 1.3166 - accuracy: 0.5214\n",
            "Epoch 2/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 1.1068 - accuracy: 0.4929\n",
            "Epoch 3/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.8919 - accuracy: 0.5393\n",
            "Epoch 4/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.8715 - accuracy: 0.5429\n",
            "Epoch 5/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.8725 - accuracy: 0.4929\n",
            "Epoch 6/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7158 - accuracy: 0.5321\n",
            "Epoch 7/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7458 - accuracy: 0.5214\n",
            "Epoch 8/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7665 - accuracy: 0.5214\n",
            "Epoch 9/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7249 - accuracy: 0.4964\n",
            "Epoch 10/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6786 - accuracy: 0.5964\n",
            "Epoch 11/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7231 - accuracy: 0.5143\n",
            "Epoch 12/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7245 - accuracy: 0.5286\n",
            "Epoch 13/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6959 - accuracy: 0.5464\n",
            "Epoch 14/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.7202 - accuracy: 0.4964\n",
            "Epoch 15/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7083 - accuracy: 0.5250\n",
            "Epoch 16/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6984 - accuracy: 0.5107\n",
            "Epoch 17/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7068 - accuracy: 0.5286\n",
            "Epoch 18/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6962 - accuracy: 0.5393\n",
            "Epoch 19/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6744 - accuracy: 0.5643\n",
            "Epoch 20/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6770 - accuracy: 0.5893\n",
            "Epoch 21/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5500\n",
            "Epoch 22/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6734 - accuracy: 0.5607\n",
            "Epoch 23/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6730 - accuracy: 0.5393\n",
            "Epoch 24/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6744 - accuracy: 0.5393\n",
            "Epoch 25/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.5429\n",
            "Epoch 26/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6745 - accuracy: 0.5643\n",
            "Epoch 27/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6674 - accuracy: 0.5714\n",
            "Epoch 28/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.5321\n",
            "Epoch 29/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6552 - accuracy: 0.5821\n",
            "Epoch 30/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.6000\n",
            "Epoch 31/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6663 - accuracy: 0.5929\n",
            "Epoch 32/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6625 - accuracy: 0.5500\n",
            "Epoch 33/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.5821\n",
            "Epoch 34/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.6250\n",
            "Epoch 35/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6804 - accuracy: 0.5536\n",
            "Epoch 36/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6660 - accuracy: 0.5893\n",
            "Epoch 37/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6585 - accuracy: 0.5893\n",
            "Epoch 38/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.6286\n",
            "Epoch 39/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6442 - accuracy: 0.5464\n",
            "Epoch 40/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.5929\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.5917\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6957 - accuracy: 0.5000\n",
            "Epoch 1/40\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 1.2571 - accuracy: 0.4893\n",
            "Epoch 2/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 1.0565 - accuracy: 0.5036\n",
            "Epoch 3/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.8268 - accuracy: 0.5536\n",
            "Epoch 4/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.8197 - accuracy: 0.5393\n",
            "Epoch 5/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.8466 - accuracy: 0.5214\n",
            "Epoch 6/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7938 - accuracy: 0.5321\n",
            "Epoch 7/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7424 - accuracy: 0.5500\n",
            "Epoch 8/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7516 - accuracy: 0.5643\n",
            "Epoch 9/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.7466 - accuracy: 0.5393\n",
            "Epoch 10/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5893\n",
            "Epoch 11/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7228 - accuracy: 0.5536\n",
            "Epoch 12/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7316 - accuracy: 0.5571\n",
            "Epoch 13/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6845 - accuracy: 0.5964\n",
            "Epoch 14/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.7037 - accuracy: 0.5893\n",
            "Epoch 15/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6984 - accuracy: 0.6000\n",
            "Epoch 16/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.6321\n",
            "Epoch 17/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6765 - accuracy: 0.6500\n",
            "Epoch 18/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6321\n",
            "Epoch 19/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6735 - accuracy: 0.6179\n",
            "Epoch 20/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.6500\n",
            "Epoch 21/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6754 - accuracy: 0.6286\n",
            "Epoch 22/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6604 - accuracy: 0.6321\n",
            "Epoch 23/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.6500\n",
            "Epoch 24/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.6464\n",
            "Epoch 25/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.6357\n",
            "Epoch 26/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.6607\n",
            "Epoch 27/40\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.6571\n",
            "Epoch 28/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.6464\n",
            "Epoch 29/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.6393\n",
            "Epoch 30/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.6357\n",
            "Epoch 31/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.6750\n",
            "Epoch 32/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.6429\n",
            "Epoch 33/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.6321\n",
            "Epoch 34/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.6536\n",
            "Epoch 35/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6142 - accuracy: 0.6786\n",
            "Epoch 36/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6012 - accuracy: 0.6893\n",
            "Epoch 37/40\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6311 - accuracy: 0.6643\n",
            "Epoch 38/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6232 - accuracy: 0.6714\n",
            "Epoch 39/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6209 - accuracy: 0.6786\n",
            "Epoch 40/40\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5969 - accuracy: 0.6964\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6320 - accuracy: 0.6000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6603 - accuracy: 0.5700\n",
            "Insominia - Validation loss & accuracy: [0.6725134253501892, 0.5916666388511658]\n",
            "Insominia - Test loss & accuracy: [0.6606029272079468, 0.6200000047683716]\n",
            "shizopherania - Validation loss & accuracy: [0.4784907102584839, 0.8083333373069763]\n",
            "shizopherania - Test loss & accuracy: [0.4100569188594818, 0.8600000143051147]\n",
            "vascula_demetia - Validation loss & accuracy: [0.60086989402771, 0.75]\n",
            "vascula_demetia - Test loss & accuracy: [0.6263007521629333, 0.699999988079071]\n",
            "MBD - Validation loss & accuracy: [0.6824286580085754, 0.5916666388511658]\n",
            "MBD - Test loss & accuracy: [0.6956814527511597, 0.5]\n",
            "Bipolar - Validation loss & accuracy: [0.6320229768753052, 0.6000000238418579]\n",
            "Bipolar - Test loss & accuracy: [0.660264253616333, 0.5699999928474426]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PART 10: Single Label Classification with balanced data using a Neural Network\n",
        "This part is very similar to Part 9, though we are now using SMOTE to balance our data before passing it into the Neural Network. The Neural Network model here has same layers as previous part 9, and operates in the same fashion. Our code loops through each dependent variable (target PDD) and calls our function which defines/creates a new Neural Network. We then have it fitted to the training data, and tested on the validation/test data.  "
      ],
      "metadata": {
        "id": "HWpvCgdf4BJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NeuralNetwork_B(X, y):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "  X_train_test, X_validation, y_train_test, y_validation = train_test_split(X_train, y_train, test_size=0.3)\n",
        "\n",
        "  # SMOTE the training data\n",
        "  smote = SMOTE(random_state=101)\n",
        "  X_train_new, y_train_new = smote.fit_resample(X_train_test, y_train_test.ravel())\n",
        "\n",
        "  # SMOTE the testing data\n",
        "  X_validate_new, y_validate_new = smote.fit_resample(X_validation, y_validation.ravel())\n",
        "\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(15, input_dim=25, activation='relu', name='Input'))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(20, activation='relu', name='Hidden1'))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(40, activation='relu', name='Hidden2'))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(50, activation='relu', name='Hidden3'))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(1, activation='sigmoid', name='Output'))\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  # conver the data to the proper tensor type\n",
        "  X_train_np = np.asarray(X_train_new).astype('int')\n",
        "\n",
        "  X_train_tensor = tf.convert_to_tensor(X_train_np)\n",
        "  y_train_tensor = tf.convert_to_tensor(y_train_new)\n",
        "\n",
        "  #train the model\n",
        "  model.fit(X_train_tensor, y_train_tensor, epochs=40, batch_size=10)\n",
        "\n",
        "  # evaluate the model with the validation data\n",
        "  X_validate_np = np.asarray(X_validate_new).astype('int')\n",
        "\n",
        "  X_validate_tensor = tf.convert_to_tensor(X_validate_np)\n",
        "  y_validate_tensor = tf.convert_to_tensor(y_validate_new)\n",
        "\n",
        "  r_val = model.evaluate(X_validate_tensor, y_validate_tensor, batch_size=10)\n",
        "\n",
        "  #evaluate the model with test data\n",
        "  X_test_np = np.asarray(X_test).astype('int')\n",
        "\n",
        "  X_test_tensor = tf.convert_to_tensor(X_test_np)\n",
        "  y_test_tensor = tf.convert_to_tensor(y_test)\n",
        "\n",
        "  r_test = model.evaluate(X_test_tensor, y_test_tensor, batch_size=10)\n",
        "\n",
        "  return r_val, r_test\n",
        "\n",
        "results2 = []\n",
        "for t in target_names:\n",
        "  x_i = data3.copy()\n",
        "  del x_i['target']\n",
        "  x_i, y_i = prep_data(x_i, t)\n",
        "  r_val, r_test = NeuralNetwork_B(x_i, y_i)\n",
        "  results2.append(f\"{t} - Validation loss & accuracy: {r_val}\")\n",
        "  results2.append(f\"{t} - Test loss & accuracy: {r_test}\")\n",
        "  result_table2.append(f'{t},Balanced,Validation,{r_val[1]}')\n",
        "  result_table2.append(f'{t},Balanced,Test,{r_test[1]}')\n",
        "for r in results2:\n",
        "  print(r)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GGO3A3cZ1WV",
        "outputId": "9448b297-8da4-40e7-be7a-fda4a21c2bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "35/35 [==============================] - 1s 2ms/step - loss: 1.5473 - accuracy: 0.4769\n",
            "Epoch 2/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0689 - accuracy: 0.5434\n",
            "Epoch 3/40\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.9637 - accuracy: 0.5145\n",
            "Epoch 4/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9184 - accuracy: 0.4942\n",
            "Epoch 5/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8144 - accuracy: 0.4595\n",
            "Epoch 6/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.5462\n",
            "Epoch 7/40\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.7324 - accuracy: 0.5491\n",
            "Epoch 8/40\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.7222 - accuracy: 0.5029\n",
            "Epoch 9/40\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.7173 - accuracy: 0.5462\n",
            "Epoch 10/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7111 - accuracy: 0.5607\n",
            "Epoch 11/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7065 - accuracy: 0.5462\n",
            "Epoch 12/40\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.7392 - accuracy: 0.4971\n",
            "Epoch 13/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7060 - accuracy: 0.5520\n",
            "Epoch 14/40\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.5780\n",
            "Epoch 15/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.5809\n",
            "Epoch 16/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.5520\n",
            "Epoch 17/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6746 - accuracy: 0.5809\n",
            "Epoch 18/40\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.6906 - accuracy: 0.5751\n",
            "Epoch 19/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7019 - accuracy: 0.5434\n",
            "Epoch 20/40\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.6757 - accuracy: 0.5838\n",
            "Epoch 21/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5809\n",
            "Epoch 22/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.5954\n",
            "Epoch 23/40\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.6795 - accuracy: 0.6127\n",
            "Epoch 24/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6655 - accuracy: 0.5751\n",
            "Epoch 25/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.6156\n",
            "Epoch 26/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.6012\n",
            "Epoch 27/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.5896\n",
            "Epoch 28/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.6474\n",
            "Epoch 29/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.6214\n",
            "Epoch 30/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6457 - accuracy: 0.6590\n",
            "Epoch 31/40\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.6256 - accuracy: 0.6647\n",
            "Epoch 32/40\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.6763\n",
            "Epoch 33/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6035 - accuracy: 0.6850\n",
            "Epoch 34/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6102 - accuracy: 0.7052\n",
            "Epoch 35/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6098 - accuracy: 0.7081\n",
            "Epoch 36/40\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5999 - accuracy: 0.7428\n",
            "Epoch 37/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7428\n",
            "Epoch 38/40\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7428\n",
            "Epoch 39/40\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7775\n",
            "Epoch 40/40\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7919\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.9000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.8763\n",
            "Epoch 1/40\n",
            "48/48 [==============================] - 1s 3ms/step - loss: 1.4994 - accuracy: 0.4576\n",
            "Epoch 2/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 1.0021 - accuracy: 0.5360\n",
            "Epoch 3/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.8953 - accuracy: 0.5233\n",
            "Epoch 4/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.8102 - accuracy: 0.5275\n",
            "Epoch 5/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.8341 - accuracy: 0.4915\n",
            "Epoch 6/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.7857 - accuracy: 0.5424\n",
            "Epoch 7/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.7257 - accuracy: 0.5657\n",
            "Epoch 8/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.7068 - accuracy: 0.5678\n",
            "Epoch 9/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6616 - accuracy: 0.6356\n",
            "Epoch 10/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6472 - accuracy: 0.6165\n",
            "Epoch 11/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.6292\n",
            "Epoch 12/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6706 - accuracy: 0.6610\n",
            "Epoch 13/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6470 - accuracy: 0.6081\n",
            "Epoch 14/40\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6398\n",
            "Epoch 15/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.6610\n",
            "Epoch 16/40\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.6088 - accuracy: 0.6695\n",
            "Epoch 17/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.6780\n",
            "Epoch 18/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6052 - accuracy: 0.7055\n",
            "Epoch 19/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.7436\n",
            "Epoch 20/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5786 - accuracy: 0.7034\n",
            "Epoch 21/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5667 - accuracy: 0.7267\n",
            "Epoch 22/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.7458\n",
            "Epoch 23/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7881\n",
            "Epoch 24/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7733\n",
            "Epoch 25/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7775\n",
            "Epoch 26/40\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.8284\n",
            "Epoch 27/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.8263\n",
            "Epoch 28/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.8305\n",
            "Epoch 29/40\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8326\n",
            "Epoch 30/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.8347\n",
            "Epoch 31/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8411\n",
            "Epoch 32/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3936 - accuracy: 0.8623\n",
            "Epoch 33/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4043 - accuracy: 0.8581\n",
            "Epoch 34/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.8517\n",
            "Epoch 35/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3790 - accuracy: 0.8411\n",
            "Epoch 36/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3275 - accuracy: 0.8983\n",
            "Epoch 37/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3222 - accuracy: 0.8835\n",
            "Epoch 38/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2935 - accuracy: 0.8877\n",
            "Epoch 39/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3162 - accuracy: 0.8792\n",
            "Epoch 40/40\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3074 - accuracy: 0.8941\n",
            "21/21 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.9369\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9485\n",
            "Epoch 1/40\n",
            "40/40 [==============================] - 1s 2ms/step - loss: 1.2061 - accuracy: 0.5000\n",
            "Epoch 2/40\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.9897 - accuracy: 0.5153\n",
            "Epoch 3/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.9148 - accuracy: 0.4898\n",
            "Epoch 4/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8177 - accuracy: 0.5332\n",
            "Epoch 5/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.8190 - accuracy: 0.4235\n",
            "Epoch 6/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7912 - accuracy: 0.4719\n",
            "Epoch 7/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7461 - accuracy: 0.4872\n",
            "Epoch 8/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7335 - accuracy: 0.4974\n",
            "Epoch 9/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7034 - accuracy: 0.5179\n",
            "Epoch 10/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7248 - accuracy: 0.4923\n",
            "Epoch 11/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7174 - accuracy: 0.5077\n",
            "Epoch 12/40\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5485\n",
            "Epoch 13/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7007 - accuracy: 0.5485\n",
            "Epoch 14/40\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.7062 - accuracy: 0.4898\n",
            "Epoch 15/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7116 - accuracy: 0.5306\n",
            "Epoch 16/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7073 - accuracy: 0.5332\n",
            "Epoch 17/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6990 - accuracy: 0.5026\n",
            "Epoch 18/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5306\n",
            "Epoch 19/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7051 - accuracy: 0.5204\n",
            "Epoch 20/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7003 - accuracy: 0.4949\n",
            "Epoch 21/40\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.5765\n",
            "Epoch 22/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7055 - accuracy: 0.4719\n",
            "Epoch 23/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5255\n",
            "Epoch 24/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6889 - accuracy: 0.5179\n",
            "Epoch 25/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6970 - accuracy: 0.5281\n",
            "Epoch 26/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.7067 - accuracy: 0.4668\n",
            "Epoch 27/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6987 - accuracy: 0.5153\n",
            "Epoch 28/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6921 - accuracy: 0.5332\n",
            "Epoch 29/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6852 - accuracy: 0.5357\n",
            "Epoch 30/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.5026\n",
            "Epoch 31/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.5204\n",
            "Epoch 32/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6967 - accuracy: 0.5026\n",
            "Epoch 33/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5204\n",
            "Epoch 34/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.5587\n",
            "Epoch 35/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6892 - accuracy: 0.5561\n",
            "Epoch 36/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6826 - accuracy: 0.5510\n",
            "Epoch 37/40\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5204\n",
            "Epoch 38/40\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6859 - accuracy: 0.5587\n",
            "Epoch 39/40\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.6819 - accuracy: 0.5281\n",
            "Epoch 40/40\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.5128\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.5641\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.6186\n",
            "Epoch 1/40\n",
            "31/31 [==============================] - 1s 3ms/step - loss: 1.5703 - accuracy: 0.4968\n",
            "Epoch 2/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 1.3177 - accuracy: 0.5258\n",
            "Epoch 3/40\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 1.0428 - accuracy: 0.4677\n",
            "Epoch 4/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.9917 - accuracy: 0.4839\n",
            "Epoch 5/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.9333 - accuracy: 0.4645\n",
            "Epoch 6/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.8826 - accuracy: 0.4742\n",
            "Epoch 7/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.8153 - accuracy: 0.5194\n",
            "Epoch 8/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7902 - accuracy: 0.5129\n",
            "Epoch 9/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7876 - accuracy: 0.4935\n",
            "Epoch 10/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7491 - accuracy: 0.5323\n",
            "Epoch 11/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7669 - accuracy: 0.5032\n",
            "Epoch 12/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.5581\n",
            "Epoch 13/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7630 - accuracy: 0.5000\n",
            "Epoch 14/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7160 - accuracy: 0.5032\n",
            "Epoch 15/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7288 - accuracy: 0.5290\n",
            "Epoch 16/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7069 - accuracy: 0.5226\n",
            "Epoch 17/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7309 - accuracy: 0.5097\n",
            "Epoch 18/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6705 - accuracy: 0.5516\n",
            "Epoch 19/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6902 - accuracy: 0.5452\n",
            "Epoch 20/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.5710\n",
            "Epoch 21/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6856 - accuracy: 0.5387\n",
            "Epoch 22/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7300 - accuracy: 0.5032\n",
            "Epoch 23/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5032\n",
            "Epoch 24/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6910 - accuracy: 0.5516\n",
            "Epoch 25/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6800 - accuracy: 0.5677\n",
            "Epoch 26/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.7004 - accuracy: 0.5452\n",
            "Epoch 27/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.5484\n",
            "Epoch 28/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6815 - accuracy: 0.5290\n",
            "Epoch 29/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6910 - accuracy: 0.5226\n",
            "Epoch 30/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.6290\n",
            "Epoch 31/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6878 - accuracy: 0.5355\n",
            "Epoch 32/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6745 - accuracy: 0.5677\n",
            "Epoch 33/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.5290\n",
            "Epoch 34/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6852 - accuracy: 0.5516\n",
            "Epoch 35/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6739 - accuracy: 0.5710\n",
            "Epoch 36/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6702 - accuracy: 0.5484\n",
            "Epoch 37/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.5774\n",
            "Epoch 38/40\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.6841 - accuracy: 0.5516\n",
            "Epoch 39/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5226\n",
            "Epoch 40/40\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6638 - accuracy: 0.6161\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.5072\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.6950 - accuracy: 0.4536\n",
            "Epoch 1/40\n",
            "32/32 [==============================] - 1s 3ms/step - loss: 1.4434 - accuracy: 0.4840\n",
            "Epoch 2/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1918 - accuracy: 0.4776\n",
            "Epoch 3/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.8658 - accuracy: 0.4936\n",
            "Epoch 4/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.9017 - accuracy: 0.5096\n",
            "Epoch 5/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7976 - accuracy: 0.5577\n",
            "Epoch 6/40\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.7884 - accuracy: 0.5032\n",
            "Epoch 7/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.5288\n",
            "Epoch 8/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7284 - accuracy: 0.5801\n",
            "Epoch 9/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7443 - accuracy: 0.5609\n",
            "Epoch 10/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7144 - accuracy: 0.5705\n",
            "Epoch 11/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7471 - accuracy: 0.5192\n",
            "Epoch 12/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7277 - accuracy: 0.5801\n",
            "Epoch 13/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7213 - accuracy: 0.5353\n",
            "Epoch 14/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7145 - accuracy: 0.5449\n",
            "Epoch 15/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7175 - accuracy: 0.5288\n",
            "Epoch 16/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7292 - accuracy: 0.5256\n",
            "Epoch 17/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.5545\n",
            "Epoch 18/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.5545\n",
            "Epoch 19/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6992 - accuracy: 0.5481\n",
            "Epoch 20/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7122 - accuracy: 0.5256\n",
            "Epoch 21/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6979 - accuracy: 0.5160\n",
            "Epoch 22/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6751 - accuracy: 0.5865\n",
            "Epoch 23/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6837 - accuracy: 0.5609\n",
            "Epoch 24/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6679 - accuracy: 0.6058\n",
            "Epoch 25/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6981 - accuracy: 0.5513\n",
            "Epoch 26/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.5801\n",
            "Epoch 27/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6732 - accuracy: 0.5545\n",
            "Epoch 28/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.5737\n",
            "Epoch 29/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.5609\n",
            "Epoch 30/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.6090\n",
            "Epoch 31/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6437 - accuracy: 0.6346\n",
            "Epoch 32/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6701 - accuracy: 0.6090\n",
            "Epoch 33/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6667 - accuracy: 0.5929\n",
            "Epoch 34/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.6154\n",
            "Epoch 35/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6248 - accuracy: 0.6699\n",
            "Epoch 36/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.6186\n",
            "Epoch 37/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6409 - accuracy: 0.6186\n",
            "Epoch 38/40\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.6474\n",
            "Epoch 39/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6247 - accuracy: 0.6795\n",
            "Epoch 40/40\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6437 - accuracy: 0.6186\n",
            "17/17 [==============================] - 0s 2ms/step - loss: 0.6008 - accuracy: 0.7824\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.7629\n",
            "Insominia - Validation loss & accuracy: [0.45471981167793274, 0.8999999761581421]\n",
            "Insominia - Test loss & accuracy: [0.46257278323173523, 0.876288652420044]\n",
            "shizopherania - Validation loss & accuracy: [0.25772595405578613, 0.9368932247161865]\n",
            "shizopherania - Test loss & accuracy: [0.21799378097057343, 0.9484536051750183]\n",
            "vascula_demetia - Validation loss & accuracy: [0.688325822353363, 0.5641025900840759]\n",
            "vascula_demetia - Test loss & accuracy: [0.684972882270813, 0.6185566782951355]\n",
            "MBD - Validation loss & accuracy: [0.6818094849586487, 0.5072463750839233]\n",
            "MBD - Test loss & accuracy: [0.6950499415397644, 0.4536082446575165]\n",
            "Bipolar - Validation loss & accuracy: [0.6008458137512207, 0.7823529243469238]\n",
            "Bipolar - Test loss & accuracy: [0.6079735159873962, 0.7628865838050842]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PART 11: Multi-Label classification with non-balanced data using Neural Network\n",
        "\n",
        "In this part, we build/evaluate the Multi-Label Neural Network described in the original study, and then get its accuracy on unbalanced data. Since this is a multi-label Neural network, the target is provided as a [N, 5] matrix, which N represents each of the 5 dependent variables (classes). The dataset The output of the model will be 5 classes which represents the accuracy of the network predicting each of the 5 targets.  \n",
        "\n",
        "This model works by first getting the 5 depedent variables out of the dataset, and then splitting the dataset into train, validate, and test sets. \n",
        "\n",
        "From here, the Neural Network is created via the keras API, and the layers are defined as described in the original study. \n",
        "\n",
        "Because the Neural Network uses tensors, we need to convert the X and y values into tensors, and then they can be passed into the model as their respective set. Training is passed into the fit function, with the validation and test set passed into the evaluate function."
      ],
      "metadata": {
        "id": "anx4Kilx20gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Dense,Input,Dropout,Flatten,Conv2D,MaxPool2D\n",
        "\n",
        "data_temp_2 = data3.copy()\n",
        "\n",
        "y = pd.DataFrame([data_temp_2.pop(x) for x in ['Insominia', 'shizopherania', 'vascula_demetia', 'MBD', 'Bipolar']]).T\n",
        "\n",
        "X = data_temp_2\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "X_train_test, X_validation, y_train_test, y_validation = train_test_split(X_train, y_train, test_size=0.3)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(15, input_dim=22, activation='relu', name='Input'))\n",
        "model.add(Dropout(0.03))\n",
        "model.add(Dense(20, activation='relu', name='Hidden1'))\n",
        "model.add(Dropout(0.03))\n",
        "model.add(Dense(20, activation='relu', name='Hidden2'))\n",
        "model.add(Dropout(0.03))\n",
        "model.add(Dense(40, activation='relu', name='Hidden3'))\n",
        "model.add(Dropout(0.03))\n",
        "model.add(Dense(5, activation='sigmoid', name='Output'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=['accuracy'])\n",
        "\n",
        "X_train_np = np.asarray(X_train_test).astype('int')\n",
        "\n",
        "X_train_tensor = tf.convert_to_tensor(X_train_np)\n",
        "y_train_tensor = tf.convert_to_tensor(y_train_test)\n",
        "\n",
        "model.fit(X_train_tensor, y_train_tensor, epochs=40, batch_size=10)\n",
        "\n",
        "\n",
        "# evaluate the model with the validation data\n",
        "X_validate_np = np.asarray(X_validation).astype('int')\n",
        "\n",
        "X_validate_tensor = tf.convert_to_tensor(X_validate_np)\n",
        "y_validate_tensor = tf.convert_to_tensor(y_validation)\n",
        "\n",
        "res_val_multi = model.evaluate(X_validate_tensor, y_validate_tensor, batch_size=10)\n",
        "print(f\"Validation Loss and Accuracy is {res_val_multi}\")\n",
        "result_table2.append(f'Multi-Label,Non-Balanced,Validation,{res_val_multi[1]}')\n",
        "\n",
        "#evaluate the model with test data\n",
        "X_test_np = np.asarray(X_test).astype('int')\n",
        "\n",
        "X_test_tensor = tf.convert_to_tensor(X_test_np)\n",
        "y_test_tensor = tf.convert_to_tensor(y_test)\n",
        "\n",
        "res_test_multi = model.evaluate(X_test_tensor, y_test_tensor, batch_size=10)\n",
        "print(f\"Test Loss and Accuracy is {res_test_multi}\")\n",
        "result_table2.append(f'Multi-Label,Non-Balanced,Test,{res_test_multi[1]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPOzdeR_cuVN",
        "outputId": "5bdc77be-7c37-4fa5-ccb9-ec1d8e6a21f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "27/27 [==============================] - 1s 3ms/step - loss: 46.1616 - accuracy: 0.4815\n",
            "Epoch 2/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 15.8439 - accuracy: 0.1481\n",
            "Epoch 3/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 11.6081 - accuracy: 0.3222\n",
            "Epoch 4/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 9.2463 - accuracy: 0.2333\n",
            "Epoch 5/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.7603 - accuracy: 0.2333\n",
            "Epoch 6/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 6.7140 - accuracy: 0.4148\n",
            "Epoch 7/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5.4102 - accuracy: 0.3037\n",
            "Epoch 8/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 4.7543 - accuracy: 0.3037\n",
            "Epoch 9/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 3.4159 - accuracy: 0.3074\n",
            "Epoch 10/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2.8823 - accuracy: 0.2481\n",
            "Epoch 11/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 2.6219 - accuracy: 0.3519\n",
            "Epoch 12/40\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 2.5644 - accuracy: 0.3148\n",
            "Epoch 13/40\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 2.2252 - accuracy: 0.2037\n",
            "Epoch 14/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.3971 - accuracy: 0.2926\n",
            "Epoch 15/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.3473 - accuracy: 0.3259\n",
            "Epoch 16/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.5717 - accuracy: 0.4519\n",
            "Epoch 17/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.2609 - accuracy: 0.5259\n",
            "Epoch 18/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0627 - accuracy: 0.4667\n",
            "Epoch 19/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8824 - accuracy: 0.5259\n",
            "Epoch 20/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8833 - accuracy: 0.5185\n",
            "Epoch 21/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0139 - accuracy: 0.5000\n",
            "Epoch 22/40\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.8112 - accuracy: 0.4741\n",
            "Epoch 23/40\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.9198 - accuracy: 0.5444\n",
            "Epoch 24/40\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.7539 - accuracy: 0.5074\n",
            "Epoch 25/40\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.7840 - accuracy: 0.5370\n",
            "Epoch 26/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8062 - accuracy: 0.5259\n",
            "Epoch 27/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7020 - accuracy: 0.5333\n",
            "Epoch 28/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.5519\n",
            "Epoch 29/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.5407\n",
            "Epoch 30/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9524 - accuracy: 0.5778\n",
            "Epoch 31/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7965 - accuracy: 0.5519\n",
            "Epoch 32/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7486 - accuracy: 0.6074\n",
            "Epoch 33/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.5704\n",
            "Epoch 34/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5755 - accuracy: 0.5481\n",
            "Epoch 35/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.5519\n",
            "Epoch 36/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.5741\n",
            "Epoch 37/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.5741\n",
            "Epoch 38/40\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6347 - accuracy: 0.5852\n",
            "Epoch 39/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.5630\n",
            "Epoch 40/40\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.5963\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.5299\n",
            "Validation Loss and Accuracy is [0.38085827231407166, 0.5299145579338074]\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.5567\n",
            "Test Loss and Accuracy is [0.4045514464378357, 0.5567010045051575]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PART 12: Multi-Lablel classificaiton with balanced data using Neural Network\n",
        "\n",
        "In the final section, we have built the Multi-Label Neural Network model for Multi-Label classifaction on balanced datasets, as described in the original study. This section has 3 main steps.\n",
        "1. Balance the dataset using SMOTE algorithm by providing single 'target' column which has concatenated all 5 binary targets. \n",
        "2. Split the 'target' into 5 separate class on the balanced data that created in 1st step. \n",
        "3. Pass the dataset, and target into the Neural Network model and evaluate, similar to structure as Part 11. \n",
        "\n",
        "The Neural Network is exactly the same as Part 11, outside of the pre-work required to balance the dataset."
      ],
      "metadata": {
        "id": "ihzgbb463Aqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "data_temp = data2.copy()\n",
        "\n",
        "y = data_temp.pop('target')\n",
        "\n",
        "X = data_temp\n",
        "\n",
        "# SMOTE the training data\n",
        "smote = SMOTE(random_state=101)\n",
        "X_new, y_new = smote.fit_resample(X, y.ravel())\n",
        "\n",
        "# Split the target class into 5 separate columns. \n",
        "y_new2 = []\n",
        "for val in y_new.ravel():\n",
        "  item = []\n",
        "  for char in val:\n",
        "    item.append(char)\n",
        "  y_new2.append(item)\n",
        "\n",
        "y_new3 = pd.DataFrame(y_new2, columns = ['Insominia', 'shizopherania', 'vascula_demetia', 'MBD', 'Bipolar']).astype('int')\n",
        "\n",
        "# Split into train/test\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y_new3, test_size=0.2)\n",
        "\n",
        "X_train_test, X_validation, y_train_test, y_validation = train_test_split(X_train, y_train, test_size=0.3)\n",
        "\n",
        "\n",
        "# The NN model\n",
        "model = Sequential()\n",
        "model.add(Dense(15, input_dim=21, activation='relu', name='Input'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(20, activation='relu', name='Hidden1'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(20, activation='relu', name='Hidden2'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(40, activation='relu', name='Hidden3'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(5, activation='sigmoid', name='Output'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=['accuracy'])\n",
        "\n",
        "X_train_np = np.asarray(X_train_test).astype('int')\n",
        "\n",
        "X_train_tensor = tf.convert_to_tensor(X_train_np)\n",
        "y_train_tensor = tf.convert_to_tensor(y_train_test)\n",
        "\n",
        "model.fit(X_train_tensor, y_train_tensor, epochs=40, batch_size=10)\n",
        "\n",
        "\n",
        "# evaluate the model with the validation data\n",
        "X_validate_np = np.asarray(X_validation).astype('int')\n",
        "\n",
        "X_validate_tensor = tf.convert_to_tensor(X_validate_np)\n",
        "y_validate_tensor = tf.convert_to_tensor(y_validation)\n",
        "\n",
        "res_val_multi = model.evaluate(X_validate_tensor, y_validate_tensor, batch_size=10)\n",
        "print(f'Validation Loss and Accuracy is {res_val_multi}')\n",
        "result_table2.append(f'Multi-Label,Balanced,Validation,{res_val_multi[1]}')\n",
        "\n",
        "X_test_np = np.asarray(X_test).astype('int')\n",
        "\n",
        "X_test_tensor = tf.convert_to_tensor(X_test_np)\n",
        "y_test_tensor = tf.convert_to_tensor(y_test)\n",
        "\n",
        "res_test_multi = model.evaluate(X_test_tensor, y_test_tensor, batch_size=10)\n",
        "print(f'Test Loss and Accuracy is {res_test_multi}')\n",
        "result_table2.append(f'Multi-Label,Balanced,Test,{res_test_multi[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2zx4DGKhidS",
        "outputId": "1730d8da-26a8-4b28-d01c-d5cc016756a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "68/68 [==============================] - 1s 3ms/step - loss: 0.8556 - accuracy: 0.2050\n",
            "Epoch 2/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.7116 - accuracy: 0.3083\n",
            "Epoch 3/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.6975 - accuracy: 0.3628\n",
            "Epoch 4/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.4071\n",
            "Epoch 5/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6648 - accuracy: 0.4027\n",
            "Epoch 6/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6510 - accuracy: 0.4513\n",
            "Epoch 7/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.4115\n",
            "Epoch 8/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.4528\n",
            "Epoch 9/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6311 - accuracy: 0.4587\n",
            "Epoch 10/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6199 - accuracy: 0.4440\n",
            "Epoch 11/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6133 - accuracy: 0.4292\n",
            "Epoch 12/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.4705\n",
            "Epoch 13/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.4690\n",
            "Epoch 14/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.4808\n",
            "Epoch 15/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.4528\n",
            "Epoch 16/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.4690\n",
            "Epoch 17/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5869 - accuracy: 0.4440\n",
            "Epoch 18/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.5074\n",
            "Epoch 19/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5838 - accuracy: 0.5147\n",
            "Epoch 20/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.4690\n",
            "Epoch 21/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.4543\n",
            "Epoch 22/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.4705\n",
            "Epoch 23/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.4558\n",
            "Epoch 24/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.4764\n",
            "Epoch 25/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.5015\n",
            "Epoch 26/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.5000\n",
            "Epoch 27/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.4690\n",
            "Epoch 28/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.4897\n",
            "Epoch 29/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.5133\n",
            "Epoch 30/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.4853\n",
            "Epoch 31/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.4749\n",
            "Epoch 32/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.5177\n",
            "Epoch 33/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.4631\n",
            "Epoch 34/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.4602\n",
            "Epoch 35/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.4646\n",
            "Epoch 36/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.4705\n",
            "Epoch 37/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.4941\n",
            "Epoch 38/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5454 - accuracy: 0.5000\n",
            "Epoch 39/40\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.4764\n",
            "Epoch 40/40\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.4440\n",
            "30/30 [==============================] - 0s 1ms/step - loss: 0.5269 - accuracy: 0.2921\n",
            "Validation Loss and Accuracy is [0.5269338488578796, 0.29209622740745544]\n",
            "25/25 [==============================] - 0s 1ms/step - loss: 0.5488 - accuracy: 0.3251\n",
            "Test Loss and Accuracy is [0.5487619042396545, 0.32510289549827576]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Machine learning models accuracy\\n')\n",
        "for r in result_table:\n",
        "  l = r.split(\",\")\n",
        "  #print(l)\n",
        "  print (\"{:<15} {:<15} {:<15}\".format(l[0], l[1], l[2]))\n",
        "  #print(' '.join(map(str, l)))\n",
        "print('\\n\\nDeep learning models accuracy\\n')\n",
        "for r in result_table2:\n",
        "  l = r.split(\",\")\n",
        "  print (\"{:<15} {:<15} {:<15} {:<15}\".format(l[0], l[1], l[2], l[3]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYzScFI-cB0u",
        "outputId": "ac46ccfb-d5b6-473d-e8f8-f922247f9845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Machine learning models accuracy\n",
            "\n",
            "MLP             Non-Balanced    0.3711340206185567\n",
            "SVM             Non-Balanced    0.3711340206185567\n",
            "RandomForest    Non-Balanced    0.4020618556701031\n",
            "DecisionTree    Non-Balanced    0.4020618556701031\n",
            "MLP             Balanced        0.35051546391752575\n",
            "SVM             Balanced        0.36082474226804123\n",
            "RandomForest    Balanced        0.3711340206185567\n",
            "DecisionTree    Balanced        0.35051546391752575\n",
            "\n",
            "\n",
            "Deep learning models accuracy\n",
            "\n",
            "Insominia       Non-Balanced    Validation      0.5916666388511658\n",
            "Insominia       Non-Balanced    Test            0.6200000047683716\n",
            "shizopherania   Non-Balanced    Validation      0.8083333373069763\n",
            "shizopherania   Non-Balanced    Test            0.8600000143051147\n",
            "vascula_demetia Non-Balanced    Validation      0.75           \n",
            "vascula_demetia Non-Balanced    Test            0.699999988079071\n",
            "MBD             Non-Balanced    Validation      0.5916666388511658\n",
            "MBD             Non-Balanced    Test            0.5            \n",
            "Bipolar         Non-Balanced    Validation      0.6000000238418579\n",
            "Bipolar         Non-Balanced    Test            0.5699999928474426\n",
            "Insominia       Balanced        Validation      0.8999999761581421\n",
            "Insominia       Balanced        Test            0.876288652420044\n",
            "shizopherania   Balanced        Validation      0.9368932247161865\n",
            "shizopherania   Balanced        Test            0.9484536051750183\n",
            "vascula_demetia Balanced        Validation      0.5641025900840759\n",
            "vascula_demetia Balanced        Test            0.6185566782951355\n",
            "MBD             Balanced        Validation      0.5072463750839233\n",
            "MBD             Balanced        Test            0.4536082446575165\n",
            "Bipolar         Balanced        Validation      0.7823529243469238\n",
            "Bipolar         Balanced        Test            0.7628865838050842\n",
            "Multi-Label     Non-Balanced    Validation      0.5299145579338074\n",
            "Multi-Label     Non-Balanced    Test            0.5567010045051575\n",
            "Multi-Label     Balanced        Validation      0.29209622740745544\n",
            "Multi-Label     Balanced        Test            0.32510289549827576\n"
          ]
        }
      ]
    }
  ]
}